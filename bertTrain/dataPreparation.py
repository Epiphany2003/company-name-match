import requests
import os
import time

# -------------------------- 1. æ ¸å¿ƒé…ç½®ï¼ˆæ ¹æ®éœ€æ±‚ä¿®æ”¹ï¼‰ --------------------------
# æ–‡ä»¶è·¯å¾„é…ç½®
SSH_KEY_PATH = "./ssh_key_suleidan"          # SSHå¯†é’¥æ–‡ä»¶ï¼ˆåŒç›®å½•ï¼‰
RAW_DATA_PATH = "data/ner_data.txt"            # åŸå§‹1Wæ¡æ•°æ®æ–‡ä»¶
ANNOTATED_SAVE_PATH = "./data/hor_train_annotated.txt"  # æœ€ç»ˆåˆå¹¶ç»“æœè·¯å¾„
TEMP_BATCH_PATH = "./temp_batch_results/"     # ä¸´æ—¶æ‰¹æ¬¡ç»“æœä¿å­˜ç›®å½•

# æ¨¡å‹ä¸æ‰¹æ¬¡é…ç½®
OLLAMA_API_URL = "http://localhost:11434/api/generate"
TARGET_MODEL = "deepseek-r1:32b"
BATCH_SIZE = 30  # æ¯æ‰¹å¤„ç†æ¡ç›®æ•°ï¼ˆå»ºè®®å…ˆæµ‹è¯•50æ¡ï¼‰
TIMEOUT = 300     # å•æ‰¹è°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
RETRY_TIMES = 3    # å¢åŠ é‡è¯•æ¬¡æ•°åˆ°3æ¬¡

# -------------------------- 2. å·¥å…·å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰ --------------------------
def init_temp_dir():
    if not os.path.exists(TEMP_BATCH_PATH):
        os.makedirs(TEMP_BATCH_PATH)
        print(f"âœ… åˆ›å»ºä¸´æ—¶æ‰¹æ¬¡ç›®å½•ï¼š{os.path.abspath(TEMP_BATCH_PATH)}")
    else:
        print(f"âœ… ä¸´æ—¶æ‰¹æ¬¡ç›®å½•å·²å­˜åœ¨ï¼š{os.path.abspath(TEMP_BATCH_PATH)}")

def read_and_split_data(file_path, batch_size):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")
    with open(file_path, "r", encoding="utf-8") as f:
        raw_lines = [line.strip() for line in f.readlines() if line.strip()]
    total_lines = len(raw_lines)
    print(f"âœ… è¯»å–åŸå§‹æ•°æ®ï¼šå…±{total_lines}æ¡æœ‰æ•ˆæ¡ç›®")

    batches = []
    for i in range(0, total_lines, batch_size):
        batch_lines = raw_lines[i:i+batch_size]
        batches.append({
            "batch_num": i//batch_size + 1,
            "content": "\n".join(batch_lines),
            "line_count": len(batch_lines)
        })
    total_batches = len(batches)
    print(f"âœ… æ‹†åˆ†å®Œæˆï¼šå…±{total_batches}æ‰¹ï¼Œæ¯æ‰¹{batch_size}æ¡ï¼ˆæœ€åä¸€æ‰¹{batches[-1]['line_count']}æ¡ï¼‰")

    completed_batches = []
    if os.path.exists(TEMP_BATCH_PATH):
        for file in os.listdir(TEMP_BATCH_PATH):
            if file.startswith("batch_") and file.endswith(".txt"):
                try:
                    batch_num = int(file.split("_")[1].split(".")[0])
                    completed_batches.append(batch_num)
                except:
                    continue
    if completed_batches:
        print(f"âš ï¸ å‘ç°å·²å®Œæˆæ‰¹æ¬¡ï¼š{sorted(completed_batches)}ï¼Œå°†è·³è¿‡è¿™äº›æ‰¹æ¬¡")
    else:
        print(f"âœ… æ— å·²å®Œæˆæ‰¹æ¬¡ï¼Œå°†ä»ç¬¬1æ‰¹å¼€å§‹å¤„ç†")

    return total_batches, batches, completed_batches

# -------------------------- 3. ä¼˜åŒ–ï¼šå•æ‰¹æ•°æ®æ ‡æ³¨ï¼ˆå¼ºåŒ–çº¦æŸ+ç»“æœæ¸…æ´—ï¼‰ --------------------------
def annotate_single_batch(batch_info):
    batch_num = batch_info["batch_num"]
    batch_content = batch_info["content"]
    batch_line_count = batch_info["line_count"]

    # ä¼˜åŒ–1ï¼šå¼ºåŒ–Promptï¼Œå¢åŠ æ ¼å¼ç¤ºä¾‹ï¼Œæ˜ç¡®æ¡ç›®æ•°è¦æ±‚
    prompt = f"""
ä»»åŠ¡ï¼šé‡æ–°æ£€æŸ¥ä»¥ä¸‹ç¬¬{batch_num}æ‰¹NERæ•°æ®ï¼ˆå…±{batch_line_count}æ¡ï¼‰ï¼Œä»…æ ‡æ³¨ã€Œå…¬å¸å…³é”®è¯ã€ï¼Œä¸¥æ ¼éµå¾ªï¼š

1. æ ‡ç­¾è§„åˆ™ï¼š
   - ä»…ä½¿ç”¨3ç§æ ‡ç­¾ï¼šB-ORGï¼ˆå…¬å¸å…³é”®è¯é¦–å­—ç¬¦ï¼‰ã€I-ORGï¼ˆå…¬å¸å…³é”®è¯åç»­å­—ç¬¦ï¼‰ã€Oï¼ˆéå…³é”®è¯å­—ç¬¦ï¼‰ï¼›
   - å…³é”®è¯å®šä¹‰ï¼šå…¬å¸åä¸­çš„æ ¸å¿ƒåç§°ï¼Œ
   - å…¬å¸åç§°ä¸€èˆ¬ç”±åœ°åŒºï¼ˆRegionï¼‰ã€å…³é”®è¯ï¼ˆXï¼‰ã€è¡Œä¸šï¼ˆIndustryï¼‰å’Œå…¬å¸åç¼€ï¼ˆOrg_Suffixï¼‰å››éƒ¨åˆ†ç»„æˆã€‚æ¯”å¦‚ã€æ·±åœ³å¸‚ä¸‡ç½‘åšé€šç§‘æŠ€æœ‰é™å…¬å¸ã€‘ï¼Œåœ°åŒºä¸ºã€æ·±åœ³å¸‚ã€‘ã€ã€ä¸‡ç½‘åšé€šã€‘æ˜¯å…³é”®è¯ã€ã€ç§‘æŠ€ã€‘æ˜¯è¡Œä¸šè¯ï¼Œã€æœ‰é™å…¬å¸æ˜¯ã€‘å…¬å¸åç¼€ã€‚æˆ‘éœ€è¦ä½ å…ˆæ’é™¤åœ°åŒºï¼ˆåŒ…æ‹¬å›½å®¶ã€å’Œä¸­å›½çš„å„ä¸ªåœ°æ–¹ï¼‰ã€è¡Œä¸šã€å¸¸è§å…¬å¸åç¼€ï¼Œå‰©ä¸‹çš„éƒ¨åˆ†å°±æ˜¯å…³é”®è¯ã€‚
   - åªéœ€è¦æ ‡å‡ºå…³é”®è¯å’Œéå…³é”®è¯å³å¯ï¼Œä½†æ˜¯å…³é”®è¯çš„å®šä½é€šè¿‡å…ˆæ’é™¤åœ°åŒºã€è¡Œä¸šã€å…¬å¸åç¼€æ¥å®ç°ã€‚

2. æ ¼å¼å¼ºåˆ¶è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œå¦åˆ™æ ‡æ³¨æ— æ•ˆï¼‰ï¼š
   - è¾“å‡ºè¡Œæ•°å¿…é¡» = {batch_line_count}æ¡ï¼ˆä¸è¾“å…¥æ¡ç›®æ•°å®Œå…¨ä¸€è‡´ï¼‰ï¼›
   - æ¯æ¡æ ¼å¼ï¼šå…¬å¸å + ç©ºæ ¼ + æ ‡ç­¾åºåˆ—ï¼ˆå¦‚â€œé˜¿é‡Œè½¯ä»¶å…¬å¸ B-ORG I-ORG O O O Oâ€ï¼‰ï¼›
   - æ ‡ç­¾åºåˆ—é•¿åº¦å¿…é¡» = å…¬å¸åå­—ç¬¦æ•°ï¼ˆå¦‚â€œé˜¿é‡Œâ€2å­—ç¬¦ â†’ æ ‡ç­¾2ä¸ªï¼‰ï¼›
   - ä¸å…è®¸æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹ï¼ˆå¦‚è§£é‡Šã€ç©ºè¡Œã€æ‰¹æ¬¡è¯´æ˜ã€æ€»ç»“æ–‡å­—ï¼‰ã€‚
   - æœ€åçš„è¾“å‡ºåªæœ‰ç¬¦åˆæ ¼å¼çš„å…¬å¸å + ç©ºæ ¼ + æ ‡ç­¾åºåˆ—

3. é”™è¯¯ç¤ºä¾‹ï¼ˆä»¥ä¸‹å‡ä¸ºé”™è¯¯ï¼Œç¦æ­¢å‡ºç°ï¼‰ï¼š
   - é”™è¯¯1ï¼šå¤šè¾“å‡ºä¸€è¡Œâ€œæ ‡æ³¨å®Œæˆâ€ï¼›
   - é”™è¯¯2ï¼šå°†â€œé˜¿é‡Œè½¯ä»¶å…¬å¸â€æ‹†åˆ†ä¸ºä¸¤è¡Œï¼›
   - é”™è¯¯3ï¼šæ ‡ç­¾åºåˆ—é•¿åº¦ä¸å…¬å¸åä¸ä¸€è‡´ã€‚

4. æ­£ç¡®ç¤ºä¾‹ï¼ˆå‡è®¾è¾“å…¥1æ¡ï¼‰ï¼š
   è¾“å…¥ï¼šé˜¿é‡Œè½¯ä»¶å…¬å¸ O O O O O O
   è¾“å‡ºï¼šé˜¿é‡Œè½¯ä»¶å…¬å¸ B-ORG I-ORG O O O O

ç¬¬{batch_num}æ‰¹åŸå§‹æ•°æ®ï¼š
{batch_content}

ç°åœ¨ï¼Œè¯·è¾“å‡º{batch_line_count}æ¡æ ‡æ³¨ç»“æœï¼ˆä»…è¾“å‡ºæ ‡æ³¨å†…å®¹ï¼Œæ— å…¶ä»–æ–‡å­—ï¼‰ï¼š
"""

    # è°ƒç”¨æ¨¡å‹ï¼ˆå¢åŠ é‡è¯•æ¬¡æ•°ï¼‰
    for retry in range(RETRY_TIMES + 1):
        try:
            response = requests.post(
                OLLAMA_API_URL,
                json={
                    "model": TARGET_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.0,  # ä¼˜åŒ–2ï¼šæ¸©åº¦è®¾ä¸º0ï¼Œæœ€å¤§é™åº¦é™ä½éšæœºæ€§
                    "max_tokens": 50000
                },
                timeout=TIMEOUT
            )
            response.raise_for_status()
            raw_annotated = response.json()["response"].strip()

            # ä¼˜åŒ–3ï¼šç»“æœæ¸…æ´—ï¼ˆè¿‡æ»¤æ— æ•ˆè¡Œï¼Œç¡®ä¿æ¡ç›®æ•°åŒ¹é…ï¼‰
            # æ­¥éª¤1ï¼šæŒ‰è¡Œæ‹†åˆ†ï¼Œè¿‡æ»¤ç©ºè¡Œå’Œä¸å«æ ‡ç­¾çš„è¡Œ
            annotated_lines = []
            for line in raw_annotated.splitlines():
                line_clean = line.strip()
                # ä»…ä¿ç•™åŒ…å«æœ‰æ•ˆæ ‡ç­¾çš„è¡Œï¼ˆé¿å…æ¨¡å‹è¾“å‡ºçš„è§£é‡Šæ–‡å­—ï¼‰
                if "O" in line_clean or "B-ORG" in line_clean or "I-ORG" in line_clean:
                    annotated_lines.append(line_clean)
            
            # æ­¥éª¤2ï¼šç¡®ä¿æœ€ç»ˆæ¡ç›®æ•°ä¸åŸå§‹ä¸€è‡´ï¼ˆæˆªå–æˆ–è¡¥å……ï¼Œæç«¯æƒ…å†µå¤„ç†ï¼‰
            ''' if len(annotated_lines) > batch_line_count:
                # è‹¥å¤šæ ‡ï¼Œå–å‰Næ¡ï¼ˆN=åŸå§‹æ•°é‡ï¼‰
                #annotated_lines = annotated_lines[:batch_line_count]
                print(f"âš ï¸ æ‰¹æ¬¡{batch_num}å¤šæ ‡ï¼Œå·²æˆªå–å‰{batch_line_count}æ¡")
            elif len(annotated_lines) < batch_line_count:
                # è‹¥å°‘æ ‡ï¼Œç”¨åŸå§‹è¡Œå¡«å……ï¼ˆé¿å…åç»­åˆå¹¶å¤±è´¥ï¼Œéœ€äººå·¥æ£€æŸ¥ï¼‰
                missing = batch_line_count - len(annotated_lines)
                raw_batch_lines = batch_content.splitlines()
                for i in range(missing):
                    # å¡«å……åŸå§‹è¡Œï¼ˆæœªæ ‡æ³¨çŠ¶æ€ï¼‰
                    annotated_lines.append(raw_batch_lines[len(annotated_lines)] if len(annotated_lines) < len(raw_batch_lines) else "")
                print(f"âš ï¸ æ‰¹æ¬¡{batch_num}å°‘æ ‡ï¼Œå·²ç”¨åŸå§‹æ•°æ®å¡«å……{missing}æ¡ï¼ˆéœ€äººå·¥æ£€æŸ¥ï¼‰") '''
            
            # é‡æ–°æ‹¼æ¥ä¸ºæ–‡æœ¬
            annotated_content = "\n".join(annotated_lines)
            print(f"âœ… æ‰¹æ¬¡{batch_num}æ ‡æ³¨å®Œæˆï¼š{batch_line_count}æ¡ï¼ˆæ¸…æ´—åï¼‰")
            return annotated_content

        except Exception as e:
            if retry < RETRY_TIMES:
                wait_time = (retry + 1) * 10
                print(f"âš ï¸ æ‰¹æ¬¡{batch_num}ç¬¬{retry+1}æ¬¡å¤±è´¥ï¼š{str(e)}ï¼Œ{wait_time}ç§’åé‡è¯•")
                time.sleep(wait_time)
            else:
                raise RuntimeError(f"æ‰¹æ¬¡{batch_num}é‡è¯•{RETRY_TIMES}æ¬¡ä»å¤±è´¥ï¼š{str(e)}")

# -------------------------- 4. ä¿å­˜ä¸åˆå¹¶å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰ --------------------------
def save_batch_result(batch_num, annotated_content):
    batch_save_path = os.path.join(TEMP_BATCH_PATH, f"batch_{batch_num}.txt")
    with open(batch_save_path, "w", encoding="utf-8") as f:
        f.write(annotated_content)
    print(f"âœ… æ‰¹æ¬¡{batch_num}ç»“æœä¿å­˜åˆ°ï¼š{batch_save_path}")

def merge_all_batches(total_batches, final_save_path):
    merged_content = []
    for batch_num in range(1, total_batches + 1):
        batch_path = os.path.join(TEMP_BATCH_PATH, f"batch_{batch_num}.txt")
        if not os.path.exists(batch_path):
            raise FileNotFoundError(f"æ‰¹æ¬¡{batch_num}ä¸´æ—¶æ–‡ä»¶ç¼ºå¤±ï¼š{batch_path}")
        with open(batch_path, "r", encoding="utf-8") as f:
            merged_content.append(f.read().strip())

    final_content = "\n".join(merged_content)
    with open(final_save_path, "w", encoding="utf-8") as f:
        f.write(final_content)

    raw_total = len([line.strip() for line in open(RAW_DATA_PATH, "r", encoding="utf-8").readlines() if line.strip()])
    final_total = len([line.strip() for line in final_content.splitlines() if line.strip()])
    print(f"\nğŸ‰ æ‰€æœ‰æ‰¹æ¬¡åˆå¹¶å®Œæˆï¼æœ€ç»ˆæ–‡ä»¶ï¼š{os.path.abspath(final_save_path)}")
    print(f"ğŸ“Š æ€»æ¡ç›®æ•°éªŒè¯ï¼šåŸå§‹{raw_total}æ¡ â†’ æ ‡æ³¨{final_total}æ¡ï¼ˆ{'åŒ¹é…' if raw_total == final_total else 'ä¸åŒ¹é…'}ï¼‰")

# -------------------------- 5. ä¸»æµç¨‹ --------------------------
if __name__ == "__main__":
    try:
        init_temp_dir()
        total_batches, all_batches, completed_batches = read_and_split_data(RAW_DATA_PATH, BATCH_SIZE)

        for batch in all_batches:
            batch_num = batch["batch_num"]
            if batch_num in completed_batches:
                print(f"â­ï¸  è·³è¿‡å·²å®Œæˆæ‰¹æ¬¡ï¼š{batch_num}")
                continue

            print(f"\nâ³ å¼€å§‹å¤„ç†æ‰¹æ¬¡{batch_num}/{total_batches}ï¼ˆ{batch['line_count']}æ¡ï¼‰")
            batch_annotated = annotate_single_batch(batch)
            save_batch_result(batch_num, batch_annotated)
            time.sleep(2)  # æ‰¹æ¬¡é—´éš”

        merge_all_batches(total_batches, ANNOTATED_SAVE_PATH)

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
        
        print("ğŸ’¡ æç¤ºï¼šå¯é‡æ–°è¿è¡Œè„šæœ¬ï¼Œå°†è‡ªåŠ¨è·³è¿‡å·²å®Œæˆæ‰¹æ¬¡")
